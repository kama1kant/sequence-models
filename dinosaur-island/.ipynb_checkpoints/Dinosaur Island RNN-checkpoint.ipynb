{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DinosDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with open('data/dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
    "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
    "        print(self.ch_to_idx)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        line = self.lines[index]\n",
    "        x_str = ' ' + line #add a space at the beginning, which indicates a vector of zeros.\n",
    "        y_str = line + '\\n'\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "        \n",
    "        y[0] = self.ch_to_idx[y_str[0]]\n",
    "        #we start from the second character because the first character of x was nothing(vector of zeros).\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str[1:], y_str[1:]), 1):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "trn_ds = DinosDataset()\n",
    "trn_dl = DataLoader(trn_ds, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear_hx = nn.Linear(input_size, hidden_size, bias=False)\n",
    "        self.linear_output = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, h_prev, x):\n",
    "        h = torch.tanh(self.linear_hh(h_prev) + self.linear_hx(x))\n",
    "        y = self.linear_output(h)\n",
    "        return h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(trn_ds.vocab_size, hidden_size, trn_ds.vocab_size).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def print_sample(sample_idxs):\n",
    "    print(trn_ds.idx_to_ch[sample_idxs[0]].upper(), end='')\n",
    "    [print(trn_ds.idx_to_ch[x], end='') for x in sample_idxs[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def sample(model):\n",
    "    model.eval()\n",
    "    word_size=0\n",
    "    newline_idx = trn_ds.ch_to_idx['\\n']\n",
    "    indices = []\n",
    "    pred_char_idx = -1\n",
    "    h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "    x = h_prev.new_zeros([1, trn_ds.vocab_size])\n",
    "    with torch.no_grad():\n",
    "        while pred_char_idx != newline_idx and word_size != 50:\n",
    "            h_prev, y_pred = model(h_prev, x)\n",
    "            softmax_scores = torch.softmax(y_pred, dim=1).cpu().numpy().ravel()\n",
    "            np.random.seed(np.random.randint(1, 5000))\n",
    "            idx = np.random.choice(np.arange(trn_ds.vocab_size), p=softmax_scores)\n",
    "            indices.append(idx)\n",
    "            \n",
    "            x = (y_pred == y_pred.max(1)[0]).float()\n",
    "            pred_char_idx = idx\n",
    "            \n",
    "            word_size += 1\n",
    "        \n",
    "        if word_size == 50:\n",
    "            indices.append(newline_idx)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loss_fn, optimizer):\n",
    "    for line_num, (x, y) in enumerate(trn_dl):\n",
    "        model.train()\n",
    "        loss = 0\n",
    "        optimizer.zero_grad()\n",
    "        h_prev = torch.zeros([1, hidden_size], dtype=torch.float, device=device)\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        for i in range(x.shape[1]):\n",
    "            h_prev, y_pred = model(h_prev, x[:, i])\n",
    "            loss += loss_fn(y_pred, y[:, i])\n",
    "            \n",
    "        if (line_num+1) % 100 == 0:\n",
    "            print_sample(sample(model))\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5) #gradient clipping\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, dataset='dinos', epochs=1):\n",
    "    for e in range(1, epochs+1):\n",
    "        print(f'{\"-\"*20} Epoch {e} {\"-\"*20}')\n",
    "        train_one_epoch(model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([8])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([5])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "Lernadris\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([8])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([27])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([24])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([18])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "Oueusnurus\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([18])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([21])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([18])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([14])\n",
      "Yujposaoakrus\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([8])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([18])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([15])\n",
      "Guacsaarus\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([20])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([6])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([8])\n",
      "y0  torch.Size([16])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([18])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([19])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([7])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([15])\n",
      "y0  torch.Size([10])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([17])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([14])\n",
      "y0  torch.Size([13])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([26])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([12])\n",
      "y0  torch.Size([11])\n",
      "y0  torch.Size([9])\n",
      "y0  torch.Size([16])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4764/1915835717.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4764/3308728518.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, dataset, epochs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{\"-\"*20} Epoch {e} {\"-\"*20}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_4764/1097029686.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_prev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print training data (used for debugging, you can ignore this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def print_ds(ds, num_examples=10):\n",
    "    for i, (x, y) in enumerate(trn_ds, 1):\n",
    "        print('*'*50)\n",
    "        x_str, y_str = '', ''\n",
    "        for idx in y:\n",
    "            y_str += trn_ds.idx_to_ch[idx.item()]\n",
    "        print(repr(y_str))\n",
    "\n",
    "        for t in x[1:]:\n",
    "            x_str += trn_ds.idx_to_ch[t.argmax().item()]\n",
    "        print(repr(x_str))\n",
    "\n",
    "        if i == num_examples:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "'aachenosaurus\\n'\n",
      "'aachenosaurus'\n",
      "**************************************************\n",
      "'aardonyx\\n'\n",
      "'aardonyx'\n",
      "**************************************************\n",
      "'abdallahsaurus\\n'\n",
      "'abdallahsaurus'\n",
      "**************************************************\n",
      "'abelisaurus\\n'\n",
      "'abelisaurus'\n",
      "**************************************************\n",
      "'abrictosaurus\\n'\n",
      "'abrictosaurus'\n"
     ]
    }
   ],
   "source": [
    "print_ds(trn_ds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
