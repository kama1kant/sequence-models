{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pdb\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.linear_f = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_u = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_c = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.linear_o = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, c_prev, h_prev, x):\n",
    "        combined = torch.cat([x, h_prev], 1)\n",
    "        f = torch.sigmoid(self.linear_f(combined))\n",
    "        u = torch.sigmoid(self.linear_u(combined))\n",
    "        c_tilde = torch.tanh(self.linear_c(combined))\n",
    "        c = f*c_prev + u*c_tilde\n",
    "        o = torch.sigmoid(self.linear_o(combined))\n",
    "        h = o*torch.tanh(c)\n",
    "        y = self.i2o(h)\n",
    "        \n",
    "        return c, h, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Name_Generator(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.init_hparams()\n",
    "        self.getData()\n",
    "        self.getModel()\n",
    "\n",
    "    def init_hparams(self):\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.hidden_size = 100\n",
    "        self.epochs = 10\n",
    "        self.lr = 1e-2\n",
    "    \n",
    "    def getData(self):\n",
    "        with open('data/dinos.txt') as f:\n",
    "            content = f.read().lower()\n",
    "            self.vocab = sorted(set(content))\n",
    "            self.vocab_size = len(self.vocab)\n",
    "            self.lines = content.splitlines()\n",
    "        self.ch_to_idx = {c:i for i, c in enumerate(self.vocab)}\n",
    "        self.idx_to_ch = {i:c for i, c in enumerate(self.vocab)}\n",
    "        print(self.ch_to_idx)\n",
    "        print(\"lines={}, vocab={}\".format(len(self.lines), self.vocab_size))\n",
    "    \n",
    "    def getBatchData(self, index):\n",
    "        line = self.lines[index]\n",
    "        x_str = ' ' + line\n",
    "        y_str = line + '\\n'\n",
    "        x = torch.zeros([len(x_str), self.vocab_size], dtype=torch.float)\n",
    "        y = torch.empty(len(x_str), dtype=torch.long)\n",
    "        \n",
    "        y[0] = self.ch_to_idx[y_str[0]]\n",
    "        for i, (x_ch, y_ch) in enumerate(zip(x_str[1:], y_str[1:]), 1):\n",
    "            x[i][self.ch_to_idx[x_ch]] = 1\n",
    "            y[i] = self.ch_to_idx[y_ch]\n",
    "                    \n",
    "        return x, y\n",
    "    \n",
    "    def getModel(self):\n",
    "        self.model = RNN(self.vocab_size, self.hidden_size, self.vocab_size).to(self.device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(self.model.parameters(), lr=self.lr)\n",
    "    \n",
    "    def print_sample(self, sample_idxs):\n",
    "        print(self.idx_to_ch[sample_idxs[0]].upper(), end='')\n",
    "        [print(self.idx_to_ch[x], end='') for x in sample_idxs[1:]]\n",
    "    \n",
    "    def sample(self):\n",
    "        self.model.eval()\n",
    "        word_size=0\n",
    "        newline_idx = self.ch_to_idx['\\n']\n",
    "        indices = []\n",
    "        pred_char_idx = -1\n",
    "        \n",
    "        c_prev = torch.zeros([1, self.hidden_size], dtype=torch.float, device=self.device)\n",
    "        h_prev = torch.zeros_like(c_prev)\n",
    "        x = c_prev.new_zeros([1, self.vocab_size])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            while pred_char_idx != newline_idx and word_size != 50:\n",
    "                c_prev, h_prev, y_pred = self.model(c_prev, h_prev, x)\n",
    "                softmax_scores = torch.softmax(y_pred, dim=1).cpu().numpy().ravel()\n",
    "                np.random.seed(np.random.randint(1, 5000))\n",
    "                idx = np.random.choice(np.arange(self.vocab_size), p=softmax_scores)\n",
    "                indices.append(idx)\n",
    "\n",
    "                x = (y_pred == y_pred.max(1)[0]).float()\n",
    "                pred_char_idx = idx\n",
    "\n",
    "                word_size += 1\n",
    "\n",
    "            if word_size == 50:\n",
    "                indices.append(newline_idx)\n",
    "        return indices\n",
    "    \n",
    "    def train(self):\n",
    "        for line_num in range(len(self.lines)):\n",
    "            x, y = self.getBatchData(line_num)\n",
    "            x = torch.unsqueeze(x, 0)\n",
    "            y = torch.unsqueeze(y, 0)\n",
    "            \n",
    "            self.model.train()\n",
    "            loss = 0\n",
    "            self.optimizer.zero_grad()\n",
    "            c_prev = torch.zeros([1, self.hidden_size], dtype=torch.float, device=self.device)\n",
    "            h_prev = torch.zeros_like(c_prev)\n",
    "            x, y = x.to(self.device), y.to(self.device)\n",
    "            for i in range(x.shape[1]):\n",
    "                c_prev, h_prev, y_pred = self.model(c_prev, h_prev, x[:, i])\n",
    "                loss += self.loss_fn(y_pred, y[:, i])\n",
    "\n",
    "            if (line_num+1) % 100 == 0:\n",
    "                self.print_sample(self.sample())\n",
    "\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 5) #gradient clipping\n",
    "            self.optimizer.step()\n",
    "\n",
    "    def fit(self):\n",
    "        for e in range(1, self.epochs+1):\n",
    "            print(f'{\"-\"*20} Epoch {e} {\"-\"*20}')\n",
    "            self.train()\n",
    "    \n",
    "    def print_ds(self, num_examples=10):\n",
    "        for i in range(len(self.lines)):\n",
    "            x, y = self.getBatchData(i)\n",
    "            print('*'*50)\n",
    "            x_str, y_str = '', ''\n",
    "            for idx in y:\n",
    "                y_str += self.idx_to_ch[idx.item()]\n",
    "            print(repr(y_str))\n",
    "\n",
    "            for t in x[1:]:\n",
    "                x_str += self.idx_to_ch[t.argmax().item()]\n",
    "            print(repr(x_str))\n",
    "\n",
    "            if i == num_examples:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "lines=1536, vocab=27\n"
     ]
    }
   ],
   "source": [
    "obj = Name_Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Epoch 1 --------------------\n",
      "Iiusuauca\n",
      "Soukcutodssnytossu\n",
      "In\n",
      "Es\n",
      "Seu\n",
      "Asn\n",
      "Lcthiau\n",
      "Iwoubtuuratsruurssu\n",
      "Ilaisasiu\n",
      "Crnaoesio\n",
      "Salvotcssspassiuu\n",
      "Prtalnaisatou\n",
      "Csnaoatoh\n",
      "Tamuruatuus\n",
      "Rrlxtostu\n",
      "-------------------- Epoch 2 --------------------\n",
      "Imahtasau\n",
      "Asnaohsar\n",
      "Tamuruesusarsasu\n",
      "Kqstaoaaru\n",
      "Rhtaeotaura\n",
      "Hataoutt\n",
      "Strnessausus\n",
      "Tainamsas\n",
      "Uadscarns\n",
      "Hascaururauua\n",
      "Prlysaurug\n",
      "Lahsaurul\n",
      "Rnaoauropa\n",
      "Kvotausus\n",
      "Rrkxnurus\n",
      "-------------------- Epoch 3 --------------------\n",
      "Imaksdauros\n",
      "Kalgsoamrts\n",
      "Nuasssaurussunsst\n",
      "Hmalngrus\n",
      "Aslaarrus\n",
      "Tbiuosaurus\n",
      "Priyssaur\n",
      "Hmalierts\n",
      "Bslaaorus\n",
      "Tbjtaurus\n",
      "Kgorlvaurus\n",
      "Inalhcros\n",
      "Csmaanrus\n",
      "Tckteurus\n",
      "Lipsaurus\n",
      "-------------------- Epoch 4 --------------------\n",
      "Uainaoarrus\n",
      "Asiannaurus\n",
      "Hvoucseurus\n",
      "Iytnosnhrus\n",
      "Sbsltcaurrs\n",
      "Tlhcseaurus\n",
      "Tsjiosaurus\n",
      "Uaioatrhs\n",
      "Uaasaarus\n",
      "Hbscaurus\n",
      "Tslkosaurus\n",
      "Tainarras\n",
      "Ubesaarts\n",
      "Ictcaurus\n",
      "Tslldurus\n",
      "-------------------- Epoch 5 --------------------\n",
      "Pstaisaurus\n",
      "Uaasnbaurus\n",
      "Tbiuosaurus\n",
      "Qrixiurus\n",
      "Hnalrdaurus\n",
      "Jalgsrarrus\n",
      "Nucsssaurus\n",
      "Snosocrur\n",
      "Scrmocrus\n",
      "Lgsnaerisaus\n",
      "Rtqnesaurus\n",
      "Rtanlcaurus\n",
      "Aerraurus\n",
      "Atantusos\n",
      "Sneseutus\n",
      "-------------------- Epoch 6 --------------------\n",
      "Suanldaurus\n",
      "Adsnasaurus\n",
      "Anwrtnaurus\n",
      "Qnysaurun\n",
      "Ibgsaurus\n",
      "Rnanesaurus\n",
      "Xpuchurus\n",
      "Qmysaurug\n",
      "Jbgsaurus\n",
      "Rnapaurus\n",
      "Amwrtgaurus\n",
      "Rnysauruk\n",
      "Laltdiurjs\n",
      "Manlotres\n",
      "Kvotaurus\n",
      "-------------------- Epoch 7 --------------------\n",
      "Rsixtsaurus\n",
      "Altcrpgurus\n",
      "Jetmiccurus\n",
      "Astsaurusaus\n",
      "Ruanalrus\n",
      "Euaehudus\n",
      "Flasatsus\n",
      "Stsnaurusausus\n",
      "Inamigrus\n",
      "Bsmaarrus\n",
      "Tciuosaurus\n",
      "Rrjxhurus\n",
      "Lecisaurus\n",
      "Snapaurus\n",
      "Anxspnrus\n",
      "-------------------- Epoch 8 --------------------\n",
      "Dsrnysaurus\n",
      "Ibgtasaurus\n",
      "Andsaunus\n",
      "Wpudiurus\n",
      "Rmysaurus\n",
      "Ibgrcaurus\n",
      "Jakdsaurus\n",
      "Xpucsiurus\n",
      "Iytnguras\n",
      "Alschuras\n",
      "Lalglrras\n",
      "Jvotaurus\n",
      "Rnnysaurur\n",
      "Mamtciuros\n",
      "Mamiiuras\n",
      "-------------------- Epoch 9 --------------------\n",
      "Ivotaurus\n",
      "Rsiytsaurus\n",
      "Altchures\n",
      "Kaldluros\n",
      "Hvotaurus\n",
      "Rriysaurus\n",
      "Ibgpcaurus\n",
      "Kalesaurus\n",
      "Wpudiurus\n",
      "Rnysaurus\n",
      "Lcgsauruc\n",
      "Rnapaurus\n",
      "Aeuosaurus\n",
      "Sonysaurus\n",
      "Lcgsaurus\n",
      "-------------------- Epoch 10 --------------------\n",
      "Snajmaurus\n",
      "Hvotaurus\n",
      "Rsiviurus\n",
      "Hnalilrus\n",
      "Aslbaurus\n",
      "Tciyskurus\n",
      "Drrivaurus\n",
      "Inagsaurus\n",
      "Rnalkhuros\n",
      "Ivotaurus\n",
      "Qrjxkurus\n",
      "Jnamhlrus\n",
      "Cpnasaurus\n",
      "Aeuotaurus\n",
      "Ssixiurus\n"
     ]
    }
   ],
   "source": [
    "obj.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "'aachenosaurus\\n'\n",
      "'aachenosaurus'\n",
      "**************************************************\n",
      "'aardonyx\\n'\n",
      "'aardonyx'\n",
      "**************************************************\n",
      "'abdallahsaurus\\n'\n",
      "'abdallahsaurus'\n",
      "**************************************************\n",
      "'abelisaurus\\n'\n",
      "'abelisaurus'\n",
      "**************************************************\n",
      "'abrictosaurus\\n'\n",
      "'abrictosaurus'\n",
      "**************************************************\n",
      "'abrosaurus\\n'\n",
      "'abrosaurus'\n"
     ]
    }
   ],
   "source": [
    "obj.print_ds(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
